{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxGP2McfBtFJ",
        "outputId": "5562d020-21a2-46d6-a9b0-9275767cfe00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime anchor-exp transformers-interpret"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rSVU_IJZCtta",
        "outputId": "a77deb86-8048-49ae-dc20-b40bf7b96102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting anchor-exp\n",
            "  Downloading anchor_exp-0.0.2.0.tar.gz (427 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers-interpret\n",
            "  Downloading transformers_interpret-0.10.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.19.3)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from anchor-exp) (3.7.5)\n",
            "Collecting captum>=0.3.1 (from transformers-interpret)\n",
            "  Downloading captum-0.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython<8.0.0,>=7.31.1 in /usr/local/lib/python3.10/dist-packages (from transformers-interpret) (7.34.0)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from transformers-interpret) (4.41.2)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum>=0.3.1->transformers-interpret) (2.3.0+cu121)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython<8.0.0,>=7.31.1->transformers-interpret)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (4.9.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.7.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (24.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->transformers-interpret) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->transformers-interpret) (0.23.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->transformers-interpret) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->transformers-interpret) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->transformers-interpret) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->transformers-interpret) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->transformers-interpret) (0.4.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (0.12.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (3.1.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (3.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers>=3.0.0->transformers-interpret) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers>=3.0.0->transformers-interpret) (4.12.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<8.0.0,>=7.31.1->transformers-interpret) (0.8.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->anchor-exp) (1.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<8.0.0,>=7.31.1->transformers-interpret) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0.0,>=7.31.1->transformers-interpret) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->anchor-exp) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->anchor-exp) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=3.0.0->transformers-interpret) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=3.0.0->transformers-interpret) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=3.0.0->transformers-interpret) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=3.0.0->transformers-interpret) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->anchor-exp) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->anchor-exp) (0.1.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum>=0.3.1->transformers-interpret) (1.13.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.6->captum>=0.3.1->transformers-interpret)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.6->captum>=0.3.1->transformers-interpret)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.6->captum>=0.3.1->transformers-interpret)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.6->captum>=0.3.1->transformers-interpret)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.6->captum>=0.3.1->transformers-interpret)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.6->captum>=0.3.1->transformers-interpret)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.6->captum>=0.3.1->transformers-interpret)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.6->captum>=0.3.1->transformers-interpret)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.6->captum>=0.3.1->transformers-interpret)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.6->captum>=0.3.1->transformers-interpret)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.6->captum>=0.3.1->transformers-interpret)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum>=0.3.1->transformers-interpret) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6->captum>=0.3.1->transformers-interpret)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->anchor-exp) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->anchor-exp) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->anchor-exp) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->anchor-exp) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->anchor-exp) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->anchor-exp) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->anchor-exp) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->anchor-exp) (3.0.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->anchor-exp) (1.14.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum>=0.3.1->transformers-interpret) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->anchor-exp) (0.1.2)\n",
            "Building wheels for collected packages: lime, anchor-exp\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283835 sha256=90edce833a835b13f77f9b109b44566b9441827da1ba1bc33f04432c8ffb9f0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/a2/af/9ac0a1a85a27f314a06b39e1f492bee1547d52549a4606ed89\n",
            "  Building wheel for anchor-exp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for anchor-exp: filename=anchor_exp-0.0.2.0-py3-none-any.whl size=433498 sha256=b9166e776ef26a5a2a9bd120d1f96675366a7ddba475743717394fde4fa6e8f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/53/45/7e4602020c5e5069ccef79f1389adb8efc4ca3c4d9891388bb\n",
            "Successfully built lime anchor-exp\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, lime, captum, transformers-interpret, anchor-exp\n",
            "Successfully installed anchor-exp-0.0.2.0 captum-0.7.0 jedi-0.19.1 lime-0.2.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 transformers-interpret-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "COLORS = {\n",
        "    'red': '\\033[91m',\n",
        "    'green': '\\033[92m',\n",
        "    'yellow': '\\033[93m',\n",
        "    'blue': '\\033[94m',\n",
        "    'magenta': '\\033[95m',\n",
        "    'cyan': '\\033[96m',\n",
        "    'bold': '\\033[1m',\n",
        "    'reset': '\\033[0m'\n",
        "}\n",
        "\n",
        "DEMET_PATH = 'drive/MyDrive/core/'\n",
        "LOGPATH = DEMET_PATH + 'logs/'\n",
        "if (os.path.exists(LOGPATH) == False):\n",
        "    os.makedirs(LOGPATH)\n",
        "else:\n",
        "    os.makedirs(LOGPATH, exist_ok=True)\n",
        "import os\n",
        "import time\n",
        "\n",
        "class Logger:\n",
        "    def __init__(self, to_file = False):\n",
        "        self.to_file = to_file\n",
        "        self.data = time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime())\n",
        "        self.path = os.path.join(LOGPATH, 'log-' + self.data + '.log')\n",
        "        self.colors = COLORS\n",
        "\n",
        "    def __str__(self):\n",
        "        if self.to_file:\n",
        "            return 'Logging to file'\n",
        "\n",
        "    def print(self, message, color = 'reset', bold = False):\n",
        "        if bold:\n",
        "            print(self.colors['bold'] + self.colors[color] + '[' + self.string_by_time() + ']:' + ' ' + self.colors['reset'] + message)\n",
        "        else:\n",
        "            print(self.colors[color] + '[' + self.string_by_time() + ']:' + ' ' + self.colors['reset'] + message)\n",
        "\n",
        "    def log(self, message):\n",
        "        if self.to_file:\n",
        "            with open(self.path, 'a') as file:\n",
        "                file.write('[' + self.string_by_time() + ']:' + ' ' + message + '\\n')\n",
        "\n",
        "    def print_and_log(self, message, color = 'reset', bold = False):\n",
        "        if bold:\n",
        "            print(self.colors['bold'] + self.colors[color] + '[' + self.string_by_time() + ']:' + ' ' + self.colors['reset'] + message)\n",
        "        else:\n",
        "            print(self.colors[color] + '[' + self.string_by_time() + ']:' + ' ' + self.colors['reset'] + message)\n",
        "        if self.to_file:\n",
        "            with open(self.path, 'a') as file:\n",
        "                file.write('[' + self.string_by_time() + ']:' + ' ' + message + '\\n')\n",
        "\n",
        "    def string_by_time(self):\n",
        "        return time.strftime('%H:%M:%S', time.localtime())\n",
        "\n",
        "logger = Logger(True)"
      ],
      "metadata": {
        "id": "tqvPaiY1CCjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYxho5qSBNlW",
        "outputId": "6e508e1f-8e6e-4b06-ca66-888a35dd3273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m[21:01:28]: \u001b[0mUsing BERT model for explanations\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "import torch\n",
        "import re\n",
        "\n",
        "\n",
        "TOKENIZER_PATH = DEMET_PATH + 'models/distilbert/distilbert-base-cased_0'\n",
        "MODEL_PATH = DEMET_PATH + 'models/distilbert/distilbert-base-cased_0'\n",
        "MODEL_NAME = 'distil-bert'\n",
        "EXPLANATION_PATH = DEMET_PATH + 'explanations/'\n",
        "DATA_PATH = DEMET_PATH + 'shuffled_data.csv'\n",
        "\n",
        "\n",
        "if 'roberta' in MODEL_NAME:\n",
        "    logger.print_and_log('Using RoBERTa model for explanations','green')\n",
        "    MODEL = RobertaForSequenceClassification.from_pretrained(MODEL_PATH, ignore_mismatched_sizes=True)\n",
        "    TOKENIZER = RobertaTokenizer.from_pretrained(TOKENIZER_PATH)\n",
        "else:\n",
        "    logger.print_and_log('Using BERT model for explanations','green')\n",
        "    TOKENIZER = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n",
        "    MODEL = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
        "\n",
        "class ExplainerConfig:\n",
        "    def __init__(self, method):\n",
        "        self.tokenizer = TOKENIZER\n",
        "        self.explanation_path = EXPLANATION_PATH\n",
        "        self.method = method\n",
        "        self.model = MODEL\n",
        "        self.model_name = MODEL_NAME\n",
        "\n",
        "    def get_model(self):\n",
        "        return self.model\n",
        "\n",
        "    def get_model_name(self):\n",
        "        return self.model_name\n",
        "\n",
        "    def get_tokenizer(self):\n",
        "        return self.tokenizer\n",
        "\n",
        "    def get_explanation_path(self):\n",
        "        return self.explanation_path\n",
        "\n",
        "    def get_method(self):\n",
        "        return self.method\n",
        "\n",
        "\n",
        "def lime_tokenizer(text):\n",
        "    cha_tokens = [\n",
        "        r'\\[CHA REPETITION\\]',\n",
        "        r'\\[CHA RETRACING\\]',\n",
        "        r'\\[CHA SHORT PAUSE\\]',\n",
        "        r'\\[CHA MEDIUM PAUSE\\]',\n",
        "        r'\\[CHA LONG PAUSE\\]',\n",
        "        r'\\[CHA TRAILING OFF\\]',\n",
        "        r'\\[CHA PHONOLOGICAL FRAGMENT\\]',\n",
        "        r'\\[CHA INTERPOSED WORD\\]',\n",
        "        r'\\[CHA FILLER\\]',\n",
        "        r'\\[CHA NON COMPLETION OF WORD\\]',\n",
        "        r'\\[CHA BELCHES\\]',\n",
        "        r'\\[CHA HISSES\\]',\n",
        "        r'\\[CHA GRUNTS\\]',\n",
        "        r'\\[CHA WHINES\\]',\n",
        "        r'\\[CHA COUGHS\\]',\n",
        "        r'\\[CHA HUMS\\]',\n",
        "        r'\\[CHA ROARS\\]',\n",
        "        r'\\[CHA WHISTLES\\]',\n",
        "        r'\\[CHA CRIES\\]',\n",
        "        r'\\[CHA LAUGHS\\]',\n",
        "        r'\\[CHA SNEEZES\\]',\n",
        "        r'\\[CHA WHIMPERS\\]',\n",
        "        r'\\[CHA GASPS\\]',\n",
        "        r'\\[CHA MOANS\\]',\n",
        "        r'\\[CHA SIGHS\\]',\n",
        "        r'\\[CHA YAWNS\\]',\n",
        "        r'\\[CHA GROANS\\]',\n",
        "        r'\\[CHA MUMBLES\\]',\n",
        "        r'\\[CHA SINGS\\]',\n",
        "        r'\\[CHA YELLS\\]',\n",
        "        r'\\[CHA GROWLS\\]',\n",
        "        r'\\[CHA PANTS\\]',\n",
        "        r'\\[CHA SQUEALS\\]',\n",
        "        r'\\[CHA VOCALIZES\\]',\n",
        "        r'\\[CHA TRAILING OFF QUESTION\\]',\n",
        "        r'\\[CHA QUESTION WITH EXCLAMATION\\]',\n",
        "        r'\\[CHA INTERRUPTION\\]',\n",
        "        r'\\[CHA INTERRUPTION OF QUESTION\\]',\n",
        "        r'\\[CHA SELFINTERRUPTION\\]',\n",
        "        r'\\[CHA SELFINTERRUPTED QUESTION\\]'\n",
        "    ]\n",
        "    pattern = '|'.join(cha_tokens) + r'|' + r'\\w+'\n",
        "    return re.findall(pattern, text)\n",
        "\n",
        "\n",
        "def get_prediction_lime(texts):\n",
        "    inputs = TOKENIZER(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = MODEL(**inputs)\n",
        "\n",
        "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1).numpy()\n",
        "    return probs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from transformers import logging\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from anchor import anchor_text\n",
        "from datetime import datetime\n",
        "from transformers_interpret import SequenceClassificationExplainer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import linear_model\n",
        "import os\n",
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "data = df['text'].tolist()\n",
        "labels = df['gt'].tolist()\n",
        "train, test, train_labels, test_labels = train_test_split(data, labels, test_size=.2, random_state=42)\n",
        "train, val, train_labels, val_labels = train_test_split(train, train_labels, test_size=.1, random_state=42)\n",
        "\n",
        "vectorizer = CountVectorizer(min_df=1)\n",
        "vectorizer.fit(train)\n",
        "train_vectors = vectorizer.transform(train)\n",
        "test_vectors = vectorizer.transform(test)\n",
        "val_vectors = vectorizer.transform(val)\n",
        "\n",
        "c = linear_model.LogisticRegression()\n",
        "c.fit(train_vectors, train_labels)\n",
        "preds = c.predict(val_vectors)\n",
        "def predict_lr(texts):\n",
        "    return c.predict(vectorizer.transform(texts))\n",
        "\n",
        "logger = Logger(True)\n",
        "\n",
        "class Explainer:\n",
        "    def __init__(self, ExplainerConfig):\n",
        "        self.method = ExplainerConfig.get_method()\n",
        "        self.explanation_path = ExplainerConfig.get_explanation_path()\n",
        "        self.tokenizer = ExplainerConfig.get_tokenizer()\n",
        "        self.model = ExplainerConfig.get_model()\n",
        "        self.explanation_path += ExplainerConfig.get_method() + '/'\n",
        "        self.explanation_path += ExplainerConfig.get_model_name() + '/'\n",
        "\n",
        "        logger.print_and_log(str('Initializing ' + self.method.upper() + ' explainer ...'), 'green')\n",
        "\n",
        "        if self.method == 'lime':\n",
        "            self.explainer = LimeTextExplainer(class_names=['Non-Dementia', 'Dementia'], split_expression=lime_tokenizer)\n",
        "\n",
        "        elif self.method == 'shap':\n",
        "            # TODO: Implement SHAP\n",
        "            pass\n",
        "\n",
        "        elif self.method == 'anchor':\n",
        "            nlp = spacy.load('en_core_web_sm')\n",
        "            self.explainer = anchor_text.AnchorText(nlp, ['Non-Dementia', 'Dementia'], use_unk_distribution = True)\n",
        "\n",
        "        elif self.method == 'transformer-interpret':\n",
        "            self.explainer = SequenceClassificationExplainer(ExplainerConfig.get_model(), ExplainerConfig.get_tokenizer())\n",
        "\n",
        "        self.tokenizer = ExplainerConfig.get_tokenizer()\n",
        "        self.explanation = None\n",
        "        self.explanation_name = ExplainerConfig.get_model_name()\n",
        "        self.explanation_name += '_'\n",
        "        self.timer_start = None\n",
        "        self.timer_end = None\n",
        "\n",
        "    def explain(self, text):\n",
        "        self.timer_start = datetime.now()\n",
        "        logger.print_and_log(str('Explaining with ' + self.method.upper() + ' ...'), 'green')\n",
        "        try:\n",
        "            if self.method == 'lime':\n",
        "                self.explanation = self.explainer.explain_instance(text, get_prediction_lime, num_features=len(text.split(' ')))\n",
        "                return self.explanation.as_list()\n",
        "\n",
        "            elif self.method == 'shap':\n",
        "                # TODO: Implement SHAP\n",
        "                pass\n",
        "\n",
        "            elif self.method == 'anchor':\n",
        "                self.explanation = self.explainer.explain_instance(text, predict_lr, verbose=False)\n",
        "                pred = self.explainer.class_names[predict_lr([text])[0]]\n",
        "                alternative =  self.explainer.class_names[1 - predict_lr([text])[0]]\n",
        "                temp = \"\"\n",
        "                temp += 'Model Predicts %s\\n' % pred\n",
        "                temp += '\\n'\n",
        "                temp += 'Examples where anchor applies and model predicts %s:\\n' % pred\n",
        "                temp += '\\n'.join([x[0] for x in self.explanation.examples(only_same_prediction=True)])\n",
        "                temp += '\\n\\nExamples where anchor applies and model predicts %s:\\n' % alternative\n",
        "                temp += '\\n'.join([x[0] for x in self.explanation.examples(only_different_prediction=True)])\n",
        "                self.explanation = temp\n",
        "                return self.explanation\n",
        "\n",
        "            elif self.method == 'transformer-interpret':\n",
        "                self.explanation = self.explainer(text, class_name='Dementia')\n",
        "                return self.explanation\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.print_and_log('Error in explaining: ' + str(e), 'red')\n",
        "\n",
        "    def save(self):\n",
        "        logger.print_and_log('Saving explanation...', 'green')\n",
        "        self.timer_end = datetime.now()\n",
        "        logger.print_and_log('Explanation took: ' + str(self.timer_end - self.timer_start), 'green')\n",
        "        if not os.path.exists(self.explanation_path):\n",
        "            os.makedirs(self.explanation_path, exist_ok=True)\n",
        "        try:\n",
        "            if self.method == 'lime':\n",
        "                self.explanation.save_to_file(self.explanation_path + self.explanation_name + datetime.now().strftime(\"%d_%m_%Y-%H_%M_%S\") + '.html')\n",
        "\n",
        "            elif self.method == 'shap':\n",
        "                # TODO: Implement SHAP\n",
        "                pass\n",
        "\n",
        "            elif self.method == 'anchor':\n",
        "                with open(self.explanation_path + self.explanation_name + datetime.now().strftime(\"%d_%m_%Y-%H_%M_%S\") + '.txt', 'w') as f:\n",
        "                    f.write(str(self.explanation))\n",
        "                time.sleep(10)\n",
        "\n",
        "            elif self.method == 'transformer-interpret':\n",
        "                self.explainer.visualize(self.explanation_path + self.explanation_name + datetime.now().strftime(\"%d_%m_%Y-%H_%M_%S\") + '.html')\n",
        "\n",
        "            with open(self.explanation_path + 'times.txt', 'a') as f:\n",
        "                f.write(str(self.timer_end - self.timer_start) + '\\n')\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.print_and_log('Error in saving explanation: ' + str(e), 'red')\n",
        "\n"
      ],
      "metadata": {
        "id": "erPGsLpVBrqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "methods = ['lime']\n",
        "\n",
        "df = pd.read_csv('drive/MyDrive/core/shuffled_data.csv')\n",
        "data = df['text'].to_list()\n",
        "\n",
        "confs = [ExplainerConfig(name) for name in methods]\n",
        "explainers = [Explainer(conf) for conf in confs]\n",
        "for explainer in explainers:\n",
        "  explainer.explain(\"\")\n",
        "  explainer.save()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrlepN0BCemf",
        "outputId": "7674fb2a-59c3-49e5-cf7f-59066b77b087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m[21:01:33]: \u001b[0mInitializing LIME explainer ...\n",
            "\u001b[92m[21:01:33]: \u001b[0mExplaining with LIME ...\n",
            "\u001b[92m[21:02:23]: \u001b[0mSaving explanation...\n",
            "\u001b[92m[21:02:23]: \u001b[0mExplanation took: 0:00:50.355885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "\n",
        "df = pd.read_csv('drive/MyDrive/core/shuffled_data.csv')\n",
        "\n",
        "CHA_TOKENS = [\n",
        "\n",
        "              '[CHA REPETITION]',\n",
        "              '[CHA RETRACING]',\n",
        "              '[CHA SHORT PAUSE]',\n",
        "              '[CHA MEDIUM PAUSE]',\n",
        "              '[CHA LONG PAUSE]',\n",
        "              '[CHA TRAILING OFF]',\n",
        "              '[CHA PHONOLOGICAL FRAGMENT]',\n",
        "              '[CHA FILLER]',\n",
        "              '[CHA NON COMPLETION OF WORD]',\n",
        "              '[CHA LAUGHS]',\n",
        "              '[CHA SIGHS]',\n",
        "              '[CHA TRAILING OFF QUESTION]',\n",
        "              '[CHA INTERRUPTION]',\n",
        "              '[CHA INTERRUPTION OF QUESTION]',\n",
        "\n",
        "              ]\n",
        "\n",
        "dementia_counts = {token: 0 for token in CHA_TOKENS}\n",
        "non_dementia_counts = {token: 0 for token in CHA_TOKENS}\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    text = row['text']\n",
        "    gt = row['gt']\n",
        "    for token in CHA_TOKENS:\n",
        "        count = len(re.findall(re.escape(token), text))\n",
        "        if gt == 1:\n",
        "            dementia_counts[token] += count\n",
        "        else:\n",
        "            non_dementia_counts[token] += count\n",
        "\n",
        "dementia_df = pd.DataFrame(list(dementia_counts.items()), columns=['token', 'count_dementia'])\n",
        "non_dementia_df = pd.DataFrame(list(non_dementia_counts.items()), columns=['token', 'count_non_dementia'])\n",
        "\n",
        "counts_df = pd.merge(dementia_df, non_dementia_df, on='token')\n",
        "\n",
        "counts_melted = pd.melt(counts_df, id_vars='token', var_name='condition', value_name='count')\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "sns.set(style=\"whitegrid\")\n",
        "sns.barplot(data=counts_melted, x='token', y='count', hue='condition', palette={'count_dementia': 'red', 'count_non_dementia': 'blue'})\n",
        "\n",
        "plt.xlabel('CHA Tokens')\n",
        "plt.ylabel('Count')\n",
        "plt.title('CHA Token Counts in Dementia and Non-Dementia Transcripts')\n",
        "plt.xticks(rotation=90, ha='center')\n",
        "plt.legend(title='Condition', labels=['Dementia', 'Non-Dementia'])\n",
        "plt.tight_layout()\n",
        "filename = f'CHA_Token_Counts.png'\n",
        "plt.savefig(DEMET_PATH + 'plots/' + filename)\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "5FbRg8I95Xd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts_df['total'] = counts_df['count_dementia'] + counts_df['count_non_dementia']\n",
        "counts_df['percentage_dementia'] = (counts_df['count_dementia'] / counts_df['total']) * 100\n",
        "counts_df['percentage_non_dementia'] = (counts_df['count_non_dementia'] / counts_df['total']) * 100\n",
        "\n",
        "for _, row in counts_df.iterrows():\n",
        "    token = row['token']\n",
        "    sizes = [row['percentage_dementia'], row['percentage_non_dementia']]\n",
        "    labels = ['Dementia', 'Non-Dementia']\n",
        "    colors = ['red', 'blue']\n",
        "    explode = (0.1, 0)\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\n",
        "    plt.title(f'Percentage Distribution for {token}')\n",
        "    plt.axis('equal')\n",
        "    filename = f'percentage_distribution_{token.strip(\"[]\").replace(\" \", \"_\")}.png'\n",
        "    plt.savefig(DEMET_PATH + 'plots/' + filename)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "I52YH4D8RO5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript_counts = {token: [] for token in CHA_TOKENS}\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    text = row['text']\n",
        "    counts = {token: len(re.findall(re.escape(token), text)) for token in CHA_TOKENS}\n",
        "    for token in CHA_TOKENS:\n",
        "        transcript_counts[token].append(counts[token])\n",
        "\n",
        "co_occurrence_df = pd.DataFrame(transcript_counts)\n",
        "\n",
        "corr_matrix = co_occurrence_df.corr()\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "plt.xticks(rotation=90, ha='center')\n",
        "plt.yticks(rotation=0)\n",
        "plt.title('Correlation Matrix of CHA Token Co-occurrences', fontsize=16)\n",
        "plt.tight_layout()\n",
        "filename = 'token_co-occurance_matrix.png'\n",
        "plt.savefig(DEMET_PATH + 'plots/' + filename, dpi=300)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "JCc9o_CFRkPD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
