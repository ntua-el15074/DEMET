{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjfnwXErapIw",
        "outputId": "2566cc87-1628-45b5-dfdc-a4dc4716919e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime torch"
      ],
      "metadata": {
        "id": "-IJiYLmIauxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "COLORS = {\n",
        "    'red': '\\033[91m',\n",
        "    'green': '\\033[92m',\n",
        "    'yellow': '\\033[93m',\n",
        "    'blue': '\\033[94m',\n",
        "    'magenta': '\\033[95m',\n",
        "    'cyan': '\\033[96m',\n",
        "    'bold': '\\033[1m',\n",
        "    'reset': '\\033[0m'\n",
        "}\n",
        "\n",
        "DEMET_PATH = 'drive/MyDrive/core/'\n",
        "LOGPATH = DEMET_PATH + 'logs/'\n",
        "if (os.path.exists(LOGPATH) == False):\n",
        "    os.makedirs(LOGPATH)\n",
        "else:\n",
        "    os.makedirs(LOGPATH, exist_ok=True)\n",
        "import os\n",
        "import time\n",
        "\n",
        "class Logger:\n",
        "    def __init__(self, to_file = False):\n",
        "        self.to_file = to_file\n",
        "        self.data = time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime())\n",
        "        self.path = os.path.join(LOGPATH, 'log-' + self.data + '.log')\n",
        "        self.colors = COLORS\n",
        "\n",
        "    def __str__(self):\n",
        "        if self.to_file:\n",
        "            return 'Logging to file'\n",
        "\n",
        "    def print(self, message, color = 'reset', bold = False):\n",
        "        if bold:\n",
        "            print(self.colors['bold'] + self.colors[color] + '[' + self.string_by_time() + ']:' + ' ' + self.colors['reset'] + message)\n",
        "        else:\n",
        "            print(self.colors[color] + '[' + self.string_by_time() + ']:' + ' ' + self.colors['reset'] + message)\n",
        "\n",
        "    def log(self, message):\n",
        "        if self.to_file:\n",
        "            with open(self.path, 'a') as file:\n",
        "                file.write('[' + self.string_by_time() + ']:' + ' ' + message + '\\n')\n",
        "\n",
        "    def print_and_log(self, message, color = 'reset', bold = False):\n",
        "        if bold:\n",
        "            print(self.colors['bold'] + self.colors[color] + '[' + self.string_by_time() + ']:' + ' ' + self.colors['reset'] + message)\n",
        "        else:\n",
        "            print(self.colors[color] + '[' + self.string_by_time() + ']:' + ' ' + self.colors['reset'] + message)\n",
        "        if self.to_file:\n",
        "            with open(self.path, 'a') as file:\n",
        "                file.write('[' + self.string_by_time() + ']:' + ' ' + message + '\\n')\n",
        "\n",
        "    def string_by_time(self):\n",
        "        return time.strftime('%H:%M:%S', time.localtime())\n",
        "\n",
        "logger = Logger(True)"
      ],
      "metadata": {
        "id": "wnFiU7GMa8-Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = '/content/drive/MyDrive/core/models/'\n",
        "CORE_PATH = '/content/drive/MyDrive/core/'\n",
        "DATA_PATH = '/content/drive/MyDrive/core/shuffled_data.csv'\n",
        "DEMET_PATH = 'drive/MyDrive/core/'\n",
        "EXPLANATION_PATH = DEMET_PATH + 'explanations/'"
      ],
      "metadata": {
        "id": "vmR2J_dZbdlF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, RobertaForSequenceClassification, RobertaTokenizer\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import torch\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "model_names = [MODEL_PATH + 'bert/' + 'bert-base-cased_0', MODEL_PATH + 'roberta/' + 'roberta-base_0', MODEL_PATH + 'distilbert/' + 'distilbert-base-cased_0']\n",
        "models = [BertForSequenceClassification.from_pretrained(model_names[0]), RobertaForSequenceClassification.from_pretrained(model_names[1]), BertForSequenceClassification.from_pretrained(model_names[2])]\n",
        "tokenizers = [BertTokenizer.from_pretrained(model_names[0]), RobertaTokenizer.from_pretrained(model_names[1]), BertTokenizer.from_pretrained(model_names[2])]\n",
        "\n",
        "def lime_tokenizer(text):\n",
        "    cha_tokens = [\n",
        "        r'\\[CHA REPETITION\\]',\n",
        "        r'\\[CHA RETRACING\\]',\n",
        "        r'\\[CHA SHORT PAUSE\\]',\n",
        "        r'\\[CHA MEDIUM PAUSE\\]',\n",
        "        r'\\[CHA LONG PAUSE\\]',\n",
        "        r'\\[CHA TRAILING OFF\\]',\n",
        "        r'\\[CHA PHONOLOGICAL FRAGMENT\\]',\n",
        "        r'\\[CHA INTERPOSED WORD\\]',\n",
        "        r'\\[CHA FILLER\\]',\n",
        "        r'\\[CHA NON COMPLETION OF WORD\\]',\n",
        "        r'\\[CHA BELCHES\\]',\n",
        "        r'\\[CHA HISSES\\]',\n",
        "        r'\\[CHA GRUNTS\\]',\n",
        "        r'\\[CHA WHINES\\]',\n",
        "        r'\\[CHA COUGHS\\]',\n",
        "        r'\\[CHA HUMS\\]',\n",
        "        r'\\[CHA ROARS\\]',\n",
        "        r'\\[CHA WHISTLES\\]',\n",
        "        r'\\[CHA CRIES\\]',\n",
        "        r'\\[CHA LAUGHS\\]',\n",
        "        r'\\[CHA SNEEZES\\]',\n",
        "        r'\\[CHA WHIMPERS\\]',\n",
        "        r'\\[CHA GASPS\\]',\n",
        "        r'\\[CHA MOANS\\]',\n",
        "        r'\\[CHA SIGHS\\]',\n",
        "        r'\\[CHA YAWNS\\]',\n",
        "        r'\\[CHA GROANS\\]',\n",
        "        r'\\[CHA MUMBLES\\]',\n",
        "        r'\\[CHA SINGS\\]',\n",
        "        r'\\[CHA YELLS\\]',\n",
        "        r'\\[CHA GROWLS\\]',\n",
        "        r'\\[CHA PANTS\\]',\n",
        "        r'\\[CHA SQUEALS\\]',\n",
        "        r'\\[CHA VOCALIZES\\]',\n",
        "        r'\\[CHA TRAILING OFF QUESTION\\]',\n",
        "        r'\\[CHA QUESTION WITH EXCLAMATION\\]',\n",
        "        r'\\[CHA INTERRUPTION\\]',\n",
        "        r'\\[CHA INTERRUPTION OF QUESTION\\]',\n",
        "        r'\\[CHA SELFINTERRUPTION\\]',\n",
        "        r'\\[CHA SELFINTERRUPTED QUESTION\\]'\n",
        "    ]\n",
        "    pattern = '|'.join(cha_tokens) + r'|' + r'\\w+'\n",
        "    return re.findall(pattern, text)\n",
        "\n",
        "explainer = LimeTextExplainer(class_names=['Non-Dementia', 'Dementia'], split_expression=lime_tokenizer)\n",
        "\n",
        "def predict(texts, model, tokenizer):\n",
        "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
        "    outputs = model(**inputs)\n",
        "    probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "    return probs.detach().numpy()\n",
        "\n",
        "#text = \"\"\n",
        "text = \"\"\n",
        "\n",
        "explanations = [explainer.explain_instance(text, lambda x: predict(x, model, tokenizer), num_features=len(text.split(' '))) for model, tokenizer in zip(models, tokenizers)]\n",
        "\n",
        "def get_lime_values(exp):\n",
        "    feature_values = exp.as_list()\n",
        "    features, values = zip(*feature_values)\n",
        "    return features, np.array(values)\n",
        "\n",
        "all_features = []\n",
        "lime_values = []\n",
        "\n",
        "for exp in explanations:\n",
        "    features, values = get_lime_values(exp)\n",
        "    all_features.append(features)\n",
        "    lime_values.append(values)\n",
        "\n",
        "unique_features = list(set(f for features in all_features for f in features))\n",
        "lime_values_aligned = []\n",
        "\n",
        "for values, features in zip(lime_values, all_features):\n",
        "    aligned_values = []\n",
        "    for uf in unique_features:\n",
        "        if uf in features:\n",
        "            aligned_values.append(values[features.index(uf)])\n",
        "        else:\n",
        "            aligned_values.append(0.0)\n",
        "    lime_values_aligned.append(np.array(aligned_values))\n",
        "\n",
        "lime_values_aligned = np.array(lime_values_aligned)\n",
        "\n",
        "weights = np.array([0.2, 0.5, 0.3])\n",
        "weights = weights / np.sum(weights)\n",
        "\n",
        "weighted_lime_values = np.average(lime_values_aligned, axis=0, weights=weights)\n",
        "\n",
        "def update_html_with_weighted_values(explanation, unique_features, weighted_lime_values):\n",
        "    html = explanation.as_html()\n",
        "    for feature, value in zip(unique_features, weighted_lime_values):\n",
        "        html = re.sub(r'({})\" data-w=\"[-+]?[0-9]*\\.?[0-9]+\"'.format(re.escape(feature)), r'\\1\" data-w=\"{}\"'.format(value), html)\n",
        "    return html\n",
        "\n",
        "weighted_html = update_html_with_weighted_values(explanations[0], unique_features, weighted_lime_values)\n",
        "\n",
        "explanation_name = 'weighted_lime_explanation_'\n",
        "file_path = os.path.join(EXPLANATION_PATH, explanation_name + datetime.now().strftime(\"%d_%m_%Y-%H_%M_%S\") + '.html')\n",
        "with open(file_path, 'w') as f:\n",
        "    f.write(weighted_html)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-7VrtnGa-tb",
        "outputId": "3998d7c7-de05-40b8-819c-449c26dc76a6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U2emZUlsg9zE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}